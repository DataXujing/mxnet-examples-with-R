nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
for(i in seq_along(batchSize)){
print(paste0("Batchsize iteration ", i, " of ", length(batchSize)))
data = mx.symbol.Variable("data")
drop0 = mx.symbol.Dropout(data = data, p = 0.4)
fc1 = mx.symbol.FullyConnected(drop0, name = "fc1", num_hidden = 256)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
drop1 = mx.symbol.Dropout(data = act1, p = 0.2)
fc2 = mx.symbol.FullyConnected(drop1, name = "fc2", num_hidden = 128)
act2 = mx.symbol.Activation(fc2, name = "relu2", act_type = "relu")
drop2 = mx.symbol.Dropout(act2, p = 0.2)
fc3 = mx.symbol.FullyConnected(act2, name = "fc3", num_hidden = 64)
act3 = mx.symbol.Activation(fc3, name = "relu3", act_type = "relu")
drop3 = mx.symbol.Dropout(act3, p = 0.2)
fc4 = mx.symbol.FullyConnected(act3, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc4, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = batchSize[i],
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
resultsTrain[i] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(resultsTrain)[i] = paste("Batchsize ",
batchSize[i], sep = "")
resultsTest[i] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(resultsTest)[i] = paste("Batchsize ",
batchSize[i], sep="")
}
################################################################################
################################## plot train ##################################
################################################################################
nnTrainError = as.data.frame(cbind(1:dim(resultsTrain)[1], resultsTrain))
colnames(nnTrainError)[1] = "epoch"
nnTrainError = melt(nnTrainError, id = "epoch")
write.csv(nnTrainError, file = "nnTrainError", row.names = FALSE, quote = FALSE)
nnTrainError = read.csv("nnTrainError", header = TRUE)
options(scipen=999)
nnTrainError$variable = factor(nnTrainError$variable)
ggplot(data = nnTrainError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "train error", limits = c(0, 1)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
################################################################################
################################## plot test ###################################
################################################################################
nnTestError = as.data.frame(cbind(1:dim(resultsTest)[1], resultsTest))
colnames(nnTestError)[1] = "epoch"
nnTestError = melt(nnTestError, id = "epoch")
write.csv(nnTestError, file = "nnTestError", row.names = FALSE, quote = FALSE)
nnTestError = read.csv("nnTestError", header = TRUE)
options(scipen=999)
nnTestError$variable = factor(nnTestError$variable)
ggplot(data = nnTestError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "test error", limits = c(0, 0.5)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
require("mxnet")
require("ggplot2")
require("reshape2")
epochs = 25
batchSize = c(10, 50, 100, 200)
resultsTrain = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
for(i in seq_along(batchSize)){
print(paste0("Batchsize iteration ", i, " of ", length(batchSize)))
data = mx.symbol.Variable("data")
drop0 = mx.symbol.Dropout(data = data, p = 0.4)
fc1 = mx.symbol.FullyConnected(drop0, name = "fc1", num_hidden = 256)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
drop1 = mx.symbol.Dropout(data = act1, p = 0.2)
fc2 = mx.symbol.FullyConnected(drop1, name = "fc2", num_hidden = 128)
act2 = mx.symbol.Activation(fc2, name = "relu2", act_type = "relu")
drop2 = mx.symbol.Dropout(act2, p = 0.2)
fc3 = mx.symbol.FullyConnected(act2, name = "fc3", num_hidden = 64)
act3 = mx.symbol.Activation(fc3, name = "relu3", act_type = "relu")
drop3 = mx.symbol.Dropout(act3, p = 0.2)
fc4 = mx.symbol.FullyConnected(act3, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc4, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = batchSize[i],
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
resultsTrain[i] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(resultsTrain)[i] = paste("Batchsize ",
batchSize[i], sep = "")
resultsTest[i] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(resultsTest)[i] = paste("Batchsize ",
batchSize[i], sep="")
}
epochs = 1
resultsTrain = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
batchSize = 100
resultsTrain = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
require("mxnet")
require("ggplot2")
require("reshape2")
epochs = 1
batchSize = 100
resultsTrain = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
print(paste0("Batchsize iteration ", i, " of ", length(batchSize)))
data = mx.symbol.Variable("data")
fc1 = mx.symbol.FullyConnected(data, name = "fc1", num_hidden = 128)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
fc2 = mx.symbol.FullyConnected(act1, name = "fc3", num_hidden = 64)
act2 = mx.symbol.Activation(fc2, name = "relu3", act_type = "relu")
fc3 = mx.symbol.FullyConnected(act2, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc3, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = 100,
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
resultsTrain[i] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(resultsTrain)[i] = paste("Batchsize ",
batchSize[i], sep = "")
resultsTest[i] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(resultsTest)[i] = paste("Batchsize ",
batchSize[i], sep="")
require("mxnet")
require("ggplot2")
require("reshape2")
epochs = 50
batchSize = 100
resultsTrain = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
resultsTest = data.frame(matrix(ncol = length(batchSize),
nrow = epochs))
data = mx.symbol.Variable("data")
fc1 = mx.symbol.FullyConnected(data, name = "fc1", num_hidden = 128)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
fc2 = mx.symbol.FullyConnected(act1, name = "fc3", num_hidden = 64)
act2 = mx.symbol.Activation(fc2, name = "relu3", act_type = "relu")
fc3 = mx.symbol.FullyConnected(act2, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc3, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = 100,
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
resultsTrain[i] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(resultsTrain)[i] = paste("Batchsize ",
batchSize[i], sep = "")
resultsTest[i] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(resultsTest)[i] = paste("Batchsize ",
batchSize[i], sep="")
################################################################################
################################## plot train ##################################
################################################################################
nnTrainError = as.data.frame(cbind(1:dim(resultsTrain)[1], resultsTrain))
colnames(nnTrainError)[1] = "epoch"
nnTrainError = melt(nnTrainError, id = "epoch")
write.csv(nnTrainError, file = "nnTrainError", row.names = FALSE, quote = FALSE)
nnTrainError = read.csv("nnTrainError", header = TRUE)
options(scipen=999)
nnTrainError$variable = factor(nnTrainError$variable)
ggplot(data = nnTrainError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "train error", limits = c(0, 1)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
################################################################################
################################## plot test ###################################
################################################################################
nnTestError = as.data.frame(cbind(1:dim(resultsTest)[1], resultsTest))
colnames(nnTestError)[1] = "epoch"
nnTestError = melt(nnTestError, id = "epoch")
write.csv(nnTestError, file = "nnTestError", row.names = FALSE, quote = FALSE)
nnTestError = read.csv("nnTestError", header = TRUE)
options(scipen=999)
nnTestError$variable = factor(nnTestError$variable)
ggplot(data = nnTestError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "test error", limits = c(0, 0.5)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
nnTrainError = as.data.frame(cbind(1:dim(resultsTrain)[1], resultsTrain))
colnames(nnTrainError)[1] = "epoch"
nnTrainError = melt(nnTrainError, id = "epoch")
write.csv(nnTrainError, file = "nnTrainError", row.names = FALSE, quote = FALSE)
nnTrainError = read.csv("nnTrainError", header = TRUE)
options(scipen=999)
nnTrainError$variable = factor(nnTrainError$variable)
ggplot(data = nnTrainError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "train error", limits = c(0, 0.1)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
################################################################################
################################## plot test ###################################
################################################################################
nnTestError = as.data.frame(cbind(1:dim(resultsTest)[1], resultsTest))
colnames(nnTestError)[1] = "epoch"
nnTestError = melt(nnTestError, id = "epoch")
write.csv(nnTestError, file = "nnTestError", row.names = FALSE, quote = FALSE)
nnTestError = read.csv("nnTestError", header = TRUE)
options(scipen=999)
nnTestError$variable = factor(nnTestError$variable)
ggplot(data = nnTestError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "test error", limits = c(0, 0.1)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "Batchsize")
getwd()
setwd("C:/Users/Niklas/mxnet-tutorials-in-R/data")
# Load the RData files
load("Train.RData")
load("Test.RData")
## Training data:
# As you can see, the dimension of the training data are 60000 rows and 784 colums
dim(trainData)
# However, we prefer 784 rows and 60000 colums,  which is a very common convention
# in many deeplearning frameworks.
trainData = t(trainData)
dim(trainData)
# Currently, the labels are categorical/one-hot encoded.
trainLabels[0:6, 0:9]
# Personally, I prefer true class labels, i.e. y element {0, 1,...,9}:
trainLabels_temp = numeric(length = dim(trainLabels)[1])
for(i in 1:9){
trainLabels_temp = trainLabels_temp + i*trainLabels[, i]
}
rm(i)
trainLabels = trainLabels_temp
rm(trainLabels_temp)
# As we can see, the results match those from the one-hot encoding:
head(trainLabels)
## Same procedure for the test data:
testData = t(testData)
testLabels_temp = numeric(length = dim(testLabels)[1])
for(i in 1:9){
testLabels_temp = testLabels_temp + i*testLabels[, i]
}
rm(i)
testLabels = testLabels_temp
rm(testLabels_temp)
require("mxnet")
require("ggplot2")
require("reshape2")
epochs = 5
batchSize = 100
results = data.frame(matrix(ncol = 2, nrow = epochs))
View(results)
colnames(results)[1] = paste("Training Error")
View(results)
colnames(results)[2i] = paste("Test Error")
colnames(results)[2] = paste("Test Error")
View(results)
epochs = 5
batchSize = 100
results = data.frame(matrix(ncol = 2, nrow = epochs))
data = mx.symbol.Variable("data")
fc1 = mx.symbol.FullyConnected(data, name = "fc1", num_hidden = 128)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
fc2 = mx.symbol.FullyConnected(act1, name = "fc3", num_hidden = 64)
act2 = mx.symbol.Activation(fc2, name = "relu3", act_type = "relu")
fc3 = mx.symbol.FullyConnected(act2, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc3, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = 100,
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
results[1] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(results)[1] = paste("Training Error")
results[2] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(results)[2] = paste("Test Error")
View(results)
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.1)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
epochs = 50
batchSize = 100
results = data.frame(matrix(ncol = 2, nrow = epochs))
data = mx.symbol.Variable("data")
fc1 = mx.symbol.FullyConnected(data, name = "fc1", num_hidden = 128)
act1 = mx.symbol.Activation(fc1, name = "relu1", act_type = "relu")
fc2 = mx.symbol.FullyConnected(act1, name = "fc3", num_hidden = 64)
act2 = mx.symbol.Activation(fc2, name = "relu3", act_type = "relu")
fc3 = mx.symbol.FullyConnected(act2, name = "fc4", num_hidden = 10)
softmax = mx.symbol.SoftmaxOutput(fc3, name = "sm")
devices = mx.cpu()
mx.set.seed(1337)
logger = mx.metric.logger$new()
model = mx.model.FeedForward.create(softmax,
X = trainData, y = trainLabels,
eval.data = list(data = testData, label = testLabels),
ctx = devices,
optimizer = "sgd",
learning.rate = 0.03,
momentum = 0.9,
wd = 0.001,
num.round = epochs,
array.batch.size = 100,
eval.metric = mx.metric.accuracy,
initializer = mx.init.uniform(0.07),
epoch.end.callback = mx.callback.log.train.metric(5, logger))
results[1] = as.numeric(lapply(logger$train, function(x) 1-x))
colnames(results)[1] = paste("Training Error")
results[2] = as.numeric(lapply(logger$eval, function(x) 1-x))
colnames(results)[2] = paste("Test Error")
################################################################################
################################# Plot Errors ##################################
################################################################################
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.5)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.25)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
getwd()
setwd("C:/Users/Niklas/mxnet-tutorials-in-R/results")
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
?ggsave
ggsave(filename = "simpleNetErrors", plot = last_plot())
ggsave(filename = "simpleNetErrors")
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave(filename = "simpleNetErrors")
test = ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave(filename = "simpleNetErrors", plot = test)
?ggsave
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave(filename = "simpleNetErrors", device = "png")
getwd()
ggsave(filename = "simpleNetErrors", device = "png", path = "results/simpleNetErrors.png")
getwd()
ggsave(filename = "simpleNetErrors", device = "png",
path = "C:/Users/Niklas/mxnet-tutorials-in-R/results/simpleNetErrors.png")
ggsave(filename = "simpleNetErrors", device = "png")
getwd()
ggsave(filename = "C:/Users/Niklas/mxnet-tutorials-in-R/results/simpleNetErrors", device = "png")
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave("simpleNetErrors", device = "png")
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "Misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave("simpleNetErrors", device = "png")
simpleNetError = as.data.frame(cbind(1:dim(results)[1], results))
colnames(simpleNetError)[1] = "epoch"
simpleNetError = melt(simpleNetError, id = "epoch")
write.csv(simpleNetError, file = "simpleNetError", row.names = FALSE, quote = FALSE)
simpleNetError = read.csv("simpleNetError", header = TRUE)
options(scipen=999)
simpleNetError$variable = factor(simpleNetError$variable)
ggplot(data = simpleNetError, aes(x = epoch, y = value, colour = variable)) +
geom_line() +
scale_y_continuous(name = "misclassification", limits = c(0, 0.2)) +
scale_x_continuous(labels = function (x) floor(x),
name = "epochs") +
labs(colour = "")
ggsave("simpleNetErrors", device = "png")
